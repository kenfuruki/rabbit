# 第３ステージ　深層学習（前編）
* 出力層の活性化関数  
  中間層の結果をそのまま活かすようにする。ただし分類のときは確率となるようにする。
  * 回帰  
    恒等写像$$ f(u)=u$$  
  * 二値分類  
    シグモイド関数 $$ f(u) = \frac{1}{1+exp(-u)}$$ 
  * 多クラス分類  
    ソフトマックス関数
     $$ f(i,u)= \frac{e^{u_i}}{\sum_{k=1}^{K} e^{u_k}}$$

* 確率的勾配降下法（SGD）  
  $$ W^{t+1} = W^t - \varepsilon \nabla E_n $$
  nはランダムに抽出
  これに対し勾配降下法は全量のデータでパラメータを学習させる。
  オンライン学習として、少しずつデータを集めながら学習させていくという点もSGD。  
  ディープラーニングにおいて、画像処理を扱う場合、画像１枚に対し学習用にデータ変換されたデータサイズは数十倍になり、データ量が膨大となるため、少量ずつ学習してパラメータを更新させるオンライン学習用いられやすい。  
----
* ミニバッチ勾配降下法  
  利用するデータ量は、訓練データの一部を利用するもの。確率的勾配降下法は訓練データ１件に対してパラメータを更新していくものであり、パラメータの更新による安定性はミニバッチの方が優れている。  
    
    
  ＜メモ　訓練データ全量を１００とすると＞  
  ・バッチ学習⇒訓練データ全量（バッチサイズ１００）を学習したのち重みとバイアスを更新する。  
  局所最適解にとらわれやすい。データが膨大になると処理がなかなか終わらない。
  $$ E = \frac1N \sum_{i=1}^{N}E_i $$  
  訓練データ数N　個々のデータの誤差をEiとしている。

  ・オンライン学習⇒訓練データ数１（バッチサイズ１）で学習したのち、重みとバイアスを更新する。個々のデータに振り回されるため安定性に欠けるが、それがかえって局所最適解に陥ることを防ぐ効果もある。  

  ・ミニバッチ学習⇒訓練データを小さな塊（例バッチサイズ１０）にして重みとバイアスを更新する。ランダムにバッチを選択するため、バッチ学習より局所最適解に陥りにくく、またオンライン学習よりまとまったデータで学習するため、学習安定性も高い。  
  バッチサイズ１０とすると、１エポックあたり１０回パラメータ更新が行われる。
----
* バックプロパゲーション（誤差逆伝播法）  
  ニューラルネットワークにおいて、中間層が多くなると、順伝播で誤差の勾配を求めるには、再帰的な計算が繰り返されるため、処理に非常に時間がかかる。  
  そこで微分の連鎖律を使用し、出力層から入力層に向かって順に微分していき、解析的にもとめていくことで、数値計算量を省略できる。最終的に誤差に対するパラメータの偏微分が軽い計算量で求まり、パラメータ更新が効率的に行える手法。  
  * 実装  
    backprp.ipynbを参照。
  
------
* 勾配消失の解決法  
  * 活性化関数の選択  
    勾配消失において、シグモイド関数の微分は最大で0.25であり、層が深くなるにつれゼロにちかづいていってしまう。１つの解決法として活性化関数にRelu関数を使用する。これは変数xがゼロより小さい場合はゼロ、ゼロより大きい場合はxをとる関数であり、勾配を損なわず次の層へいくことができる。マイナスをとるとゼロになることからスパース化にも寄与する。  
    numpyであらわすと、np.maximum(0, x)となる。  
  * 重みの初期値の設定  
    勾配消失対策として、重みの初期値設定がある。重みの初期値はゼロにしてしまうと、重み更新が均一な更新になってしまうため表現力がなくなってしまう。そのため、初期値は乱数をセットすることが一般的で、その上でさらにXavierを施すなどする。  
    Xavierとは、活性化関数と前のノード数によって以下になる。  
    $$ 活性化関数がシグモイド関数のときNを前のノード数として　\sqrt{1/N} $$  
    $$ 活性化関数がRelu関数のときNを前のノード数として　\sqrt{2/N}$$  
  * バッチ正規化  
    ミニバッチ単位で入力データの偏りを抑制。  
    ミニバッチ単位に、平均⇒分散⇒正規化⇒バイアス加算を実施。
    バッチサイズは２の倍数にすることが慣例。（コンピュータの扱いやすい数字とするため）  
    活性化関数に渡す前後にバッチ正規化処理を踏まえた層を加える。  
    これにより、学習データが正規化され、ばらつきがおさえられ、過学習がおさえられる。  
    ミニバッチの画像処理の場合は、GPUなら1～64枚の画像データを取り扱う。TPUだと1～256枚。  
---
* 最適化  
  勾配降下法では学習率を利用してパラメータの変化量を調整していた。最適化はこの学習率の決め方を工夫するもの。  
  * モメンタム  
    <特徴>  
    局所的最適解にならず、大局的最適解となる。  
    谷間についてから最も低い位置（最適解）にいくまでの収束時間が早い。  
    <数式>  
    式は勾配降下法に慣性項（μ）が追加されたもの。
     $$ V_t = \mu V_{t-1} - \varepsilon \Delta E $$ 
     $$ W^{t+1} = W^t + V_t $$
     よって
     $$ W^{t+1} = W^t + \mu V_{t-1} - \varepsilon \Delta E $$
  * AdaGrad  
    <特徴>  
    勾配の緩やかな斜面を得意とする。
    鞍点問題には弱い。  
    <数式>  
    $$ h_0 = \theta $$
    $$ h_t = h_{t-1} + (\Delta E)^2 $$
    $$ W^{t+1} = W^t - \varepsilon \frac{1}{\sqrt{h_t} + \theta} \Delta E $$
  * RMS Prop  
    <特徴>  
    AdaGradの進化形。AdaGradのhの部分だけ変更されたもの。  
    局所的最適解にならず、大局的最適解に向かう。  
    ハイパーパラメータの調整が必要な場合が少ない。学習率に着目して重みの振動を抑える働きをする。  
    <数式>AdaGradと違うところだけ記載。  
    $$ h_t = \alpha h_{t-1} + (1-\alpha)(\Delta E)^2$$
  * Adom  
    <特徴>  
    現在デファクトスタンダード的な存在。ほとんどのモデルで用いられる。モメンタムのメリットとRMSPropのメリットの双方をかけ合わせたもの。移動平均で振動を抑制し（モメンタム）、さらに学習率を調整して振動を抑制（RMSProp）させた。  
    
---
* 過学習  
  ニューラルネットワークは自由度が高いが、その代わり学習データにフィットしすぎて過学習になりやすい。  
  過学習になっているとき、それは重みの一部が大きすぎる状態。この際一部の入力に極端に反応しすぎてしまい汎化性能が落ちてしまう。  
  よって誤差に対して、正則化項を加算し重みを抑制する。これにより誤差を小さくしつつ、正則化項も小さくする必要があるので大きな重みになりづらくなる。  
  * L1、L2正則化（ラッソ、リッジ）  
    誤差関数にpノルムを加える。  
    $$ E_n(W) + \frac{1}{p} \lambda ||x|| $$
    L1（ラッソ）は重みがゼロになることからスパース推定。  
    L2（リッジ）は重みは小さく抑えることから縮小推定となる。  
  * ドロップアウト  
    ランダムにノードを削除して学習させること。
---
* CNN  
  CNNは画像処理でよく用いられる。入力層から畳みこみ層、プーリング層を介して全結合層に入ってくる。全結合層は、通常のニューラルネットワークになっており、その前の畳みこみ層やプーリング層において３次元（縦、横、RGB）のデータをその相関関係を維持したまま特徴量を次に伝えることができる。  
  * パディング  
    入力画像の周りに空間を設ける。これをすることにより、畳みこみ演算を実施した時に、出力画像を入力画像と同じサイズにすることができるようになる。空間に入れる数はゼロでも他の数でもよし。  
  * ストライド  
    フィルターを動かす量。大きいほど出力画像サイズは小さくなる。  
  * パディングとストライドによる出力画像サイズの計算  
    出力サイズの高さ、幅を$ O_h,O_w$として、フィルタサイズの高さと幅を$F_h,F_w$とする。そして、パディングとストライドを$P,S$とした場合  
    $$ O_h=\frac{H+2P-F_h}{S} +1$$
    $$ O_w=\frac{W+2P-F_w}{S} +1$$
    となる。
  * プーリング層  
    畳みこみ層の後に適用されることが多い。入力データをより扱いやすくするために情報を圧縮する。  
    max poolingという手法では小領域に対して最大のものを選択する処理となる。情報を圧縮することで、ある程度の過学習を抑制したり、計算コストを下げたりすることができる。