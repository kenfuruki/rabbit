# 第４ステージ　深層学習（後編）day4
* 強化学習の概要  
  長期的に報酬を最大化できるように環境の中で行動の選択ができるエージェントを作ることを目標とする機械学習の一分野。  
  行動の結果として与えられる利益をもとに行動を決定する原理を改善していく仕組みであり、教師あり学習や教師なし学習などのデータの特徴量を導き出すものとは、また違うもの。  
    * 探索と利用のトレードオフ  
      未知のものにあたりデータ取得　⇒　失敗もあり。  
      過去の成功も利用　⇒　成功はするが学ばない。  
    * 強化学習の発展  
      関数近似法とQ学習（NN）を組み合わせることで近年発展。  
    * 価値関数  
      行動価値関数と状態価値関数があり、Q学習で用いられるのは行動価値関数となる。強化学習の報酬にあたる関数となる。  
    * 方策関数  
      方策ベースの強化学習において、ある状態でどのような行動をとるのかの確率を与える関数。  
  
* 強化学習の数式  
  * 方策関数、状態行動関数  
    $$ 方策関数　：　\pi(s) = a $$
    $$ 状態＋行動関数　：　Q^\pi(s,a)  $$
  * 方策勾配法  
    $$ \theta^{t+1} = \theta^t + \epsilon \nabla J(\theta) $$
    Jは方策の良さ（定義が必要）。勾配法が従来の重み更新と異なるところは、学習率がかかっている項がプラスになっていること。これはなるべく多くの報酬を得たいことを求めるため。  
* シンプルな強化学習の実装  
  参考文献 「Udemy　みんなの強化学習（by我妻幸長氏）」  
   01_simple_reinforcement_learning.ipynb
  
---  
* ApphaGoの概要  
  2つのニューラルネットワークがある。PolicyNet,ValueNetがあり、方策関数と価値関数に相当するもの。  
  AlphaGoにはLeeとZeroがあり、Zeroの方は２つのネットワークの共通的なものを同じにして１つのネットワーク構造としている。  
  * AlphaGo Leeと比較し、Zeroの特徴  
    1. 教師あり学習を一切行わず、強化学習のみで作成  
    2. 特徴入力からヒューリスティックな要素を排除し石の配置のみとした。  
    3. PolicyNetとValueNetを１つのネットワークに統合した。  
    4. ResidualNetを導入した。  
    5. モンテカルロ木探索からRolloutシミュレーションをなくした。   
  * Residual Network  
    ショートカット構造を追加して勾配の爆発や消失を抑える効果を狙ったもの。  
    Convolution→BatchNorm→Relu→Convolution→BatchNorm→add→Reluのブロックを１単位にして積み重ねたものを基本構造とする。  
    Zeroはこれを39層にしているため、ResidualNetworkを使うことにより層数の違うネットワークとなり、アンサンブル効果が得られるという説もある。  
  * Residual Networkの工夫  
    1. ResidualNetworkの工夫  
      (1) Bottleneck  
        １層目で次元削減を行って、３層目で次元を復元する３層構造にして、２層のものに比べて計算量は同じだが１層増やせるメリットがある。  
      (2) PreActivation  
        ResidualBlockの並び順を  
        Batch→Relu→Convolution→Batch→Relu→Convolution→Add  
        とすることにより性能が向上したとするもの。  
    2. Network構造の工夫  
      (1) WideResNet  
        Convolutionのフィルタをkk倍に段階的に幅を増やしていくResNet。  
        フィルタを増やすことで深い層と同等以上の精度  
      (2) PyramidNet  
        WideResNetのように段階的にフィルタを増やすのではなく、各層でフィルタを増やすResNet。  
---  
* 軽量化、高速化  
  いかに早く学習させるか　→(モデル並列、データ並列、GPU)  
  いかにモデルを軽くするか →(量子化、蒸留、プルーニング)  
  * データ並列化（同期型）  
    各ワーカー（計算資源＝PC等）が計算がおわるのを待ち、全ワーカーの勾配が出たところで勾配の平均を計算し、親モデルのパラメータを更新する。  
  * データ並列化（非同期型）  
    各ワーカーは互いの計算を待たず、各子モデルごとに更新を行う。学習がおわった子モデルはパラメータサーバにPushされる。新たにに学習を始めるときは、パラメータサーバからPopしたモデルに対して学習を行う。  
  * 同期型と非同期型の比較  
    * 処理のスピードは互いのワーカーの計算を待たない非同期型の方が早い。  
    * 非同期は最新のモデルのパラメータを利用できないので学習が不安定になりやすい。  
    * 現在は同期型の方が精度が高いことが多いため主流は同期型。  
  * モデル並列化  
    親モデルを各ワーカーに分割し、それぞれのモデルを学習させる。全てのデータが学習が終わった後で、一つのモデルに復元。  
    モデルが大きい時はモデル並列化を、データが大きい時はデータ並列化を選択すると良い。  
    モデル並列化は、データ並列化と異なり同じPCでやることが多い。理由はモデル復元時にデータを集めて出力関数などへの計算が必要となり、異なるPCなどにしているとそのデータ収集するためのネットワーク負荷の方が時間的にかかることがあるため。  
  * GPUによる高速化  
    コア・・・GPUは低性能が多数。CPUは高性能で少数。  
    計算・・・GPUは簡単な並列処理が得意。CPUは複雑で連続的な処理が得意。  
    ニューラルネットワークは単純な行列計算なのでGPUでの並列処理向き。  
  * 量子化  
    ネットワークが大きくなると大量のパラメータが必要となり、学習や推論に多くのメモリと演算処理が必要となる。  
    そのため通常のパラメータの64bit浮動小数点を32bitなど下位の精度に落とすことでメモリと演算処理の削減を行う。  
    有効桁が小さいと重みの表現が限定されモデル精度は落ちるとされているが実際はそれほど精度は変わらない。  
  * 蒸留  
    精度の高いモデルはニューロンの規模が大きいモデル。推論に多くのメモリと演算処理が必要。  
    規模の大きなモデルの知識を使い、軽量なモデルの作成を行う。  
    *  教師モデルと生徒モデル  
      教師モデルの重みを固定し生徒モデルの重みを更新していく。誤差は教師モデルと生徒モデルのそれぞれの誤差を使い、重みを更新していく。  
  * プルーニング  
    ネットワークが大きくなると大量のパラメータになるが、すべてのニューロンの計算が精度に寄与しているわけではない。  
    モデルの精度に寄与が少ないニューロンを削減することでモデルの軽量化、高速化を見込む。  
  
---  
* 応用技術(MobileNet)  
  Depthwise Separable Convolution(Depthwise ConvolutionとPointwise Convolution)という仕組みを用いて画像認識において軽量化・高速化・高精度化したモデル。  
  全体の計算量はDepthwise Convolutionの計算量+Pointwise Convolutionの計算量となる。  
  * 一般的な畳みこみの計算量  
    高さ H、幅 W、カーネルのサイズ K、チャンネル C、フィルタ数 Mとすると以下のようになる。  
    入力特徴マップ（チャネル数）：H×W×C  
    カーネル：K×K×C  
    出力マップ：H×W×M  
    *  ストライド1でパディングありの場合の畳み込み計算量  
      ある1点の計算量：K×K×C×M  
      全出力マップの計算量：H×W×K×K×C×M  
  * Depthwise Convolution  
    フィルタ数は１で固定、１つのチャネルごとに計算。  
    計算量は、H x W x C x K x K。  
  * Pointwise Convolution  
    カーネルを１X１で固定、フィルタ数は任意。  
    計算量は、H x W x C x M。  
  
* 応用技術（DenseNet）  
  Dense Blockという仕組みを用いた画像認識モデル。  
  Dense Blockで前の各層の入力を使うことでチャンネル数が増えTransition Layerで特徴量の抽出を繰り返していく。  
    * DensNetsとResNetsの違い  
      * DenseBlockでは前方の各層からの出力すべてが後方の層への入力として用いられる。  
      * Ressidual Blockでは前１層の入力のみ後方の層への入力  
    * 成長率（Growth Rate）  
      DenseNetsのハイパーパラメータ。  
      DenseBlock内の各ブロック毎にK個ずつ特徴マップのチャネル数が増加していくとき、Kを成長率という。  
  
* 応用技術（Batch Norm）  
  * レイヤー間を流れるデータの分布をミニバッチ単位で平均０、分散１になるように正規化。  
  * 学習時間の短縮や初期値への依存低減、過学習の抑制  
  * 問題点  
    * BatchSizeが小さい条件下では、学習が収束しないことがある。  
      代わりにLayerNormなどの正規化手法が使われることが多い。  
      (GPUなどのメモリサイズが限定されることによりBatchSizeもおのずときまってしまうため、使いづらい。)  
* 応用技術（Layer Norm）  
  それぞれのsampleの全てのピクセルが同一分布に従うように正規化。  
* 応用技術（Instance Norm）
  ピクセルの他、さらにチャネルも同一分布に従うように正規化。  
* 応用技術（WaveNet 音声生成モデル）  
  * 時系列データに対して畳み込み（Dilated Convolution）を適用する。  
  * Dilated Convolution  
    層が深くなるにつれて畳み込むリンクを離す。  
    時間的に過去の情報を幅広くひろえる。つまりパラメータに対する受容野が広い。  
  
---  
* 物体検知  
  ①classification （分類）・・出力：クラスラベル  
  ②Object Ditection　（物体検知）・・出力：Bounding Box(BB)  
  ③Semantic Segmentation （意味領域分割）・・出力：各ピクセルに対し単一のクラスラベル  
  ④Instance Segmentation （個体領域分割）  
  ①から④に向かって難易度は高くなる。  
  * Confusion Matrix （混同行列）  
    $$ precision = \frac{TP}{TP + FP}  $$  
    $$ Recall = \frac{TP}{TP+FN} $$
---  
* DCGAN  
  * GANについて  
    生成器と識別器を競わせて学習する生成＆識別モデル  
    Generator : 乱数からデータ生成  
    Discriminator ：入力データが真データ（学習データ）かどうか識別する。  
  * 2プレイヤーのミニマックスゲーム  
    * 一人が自分の勝利する確率を最大化する作戦を取る。  
    * もう一人は相手が勝利する確率を最小化する作戦を取る。  
  * 価値関数V  
    GANでは価値関数Vに対し、Dが最大化、Gが最小化を行う。  
    $$ min_G max_D V(D,G)$$
    $$ V(D,G) = E_{x-P_{data(x)}}[logD(x)] + E_{z-P_z(z)}[log(1-D(G(Z)))]