# 第２ステージ 機械学習レポート
## １章　線形回帰
* 単回帰モデル 
  * モデル  
説明変数が一次元であり、説明変数に対して目的変数が線形的な関係を持つ場合に適用する。  
  $$ \hat{y} = w_0 + w_1 x \\
  \hat{y} :予測値
  $$  
  * 実装  
    ファイルの`tankaiki.ipynb`を参照。
    入力データxに対して、中心化を行い、$$ \hat{y}=w_1 x $$としたときに、傾きw1は、  
    $$ 傾き w_1 = \frac{\sum_{i=1}^{N}xy}{\sum_{i=1}^{N}x^2} $$  
    で求まるため、これを実装したもの。  

* 重回帰モデル  
  * モデル  
  単回帰モデルと異なるのは、説明変数が２つ以上となること。 
  　　$$ \hat{y} = w_0 + w_1 x_1 + w_2 x_2 +・・+w_m x_m $$
    行列に置き換えると、  
      $$ \boldsymbol{y} = X \boldsymbol{w} \\
      ただし、\\
      X = (\boldsymbol{x_1},・・・,\boldsymbol{x_n})^T  \quad n:入力データ数 \\
      \boldsymbol{x_i} = (1,x_{i1},・・・・x_{im})^T\\
      \boldsymbol{y} = (y_1,y_2・・・,y_n)^T $$  
  * 実装  
  ファイルの`jukaiki.ipynb`を参照。  
    $$ 最小二乗法より、誤差が最も低いｗは、\\
    w \quad = \quad {(\tilde{X}^T \tilde{X})}^{-1} \tilde{X}^T \boldsymbol{y} $$  
    入力データは人口的に与えたデータにし、あらかじめ設定したｗのパラメータの正解を求めたyに対して  
    重回帰を適用し、あらかじめ設定したwとどこまで近い値が算出されるかを確認した。
  
## ２章　非線形回帰  
* 多項式回帰モデル  
  * モデル  
  基本的には、前述した回帰モデルと相違ない。
  Xの行列に、関数φ（x）として計算する。
  * 実装  
  ファイルの`polyreg,ipynb`にて実装。
  ２乗、３乗と徐々に大きくしていくと、データにフィットしていくものの明らかに学習したデータ以外の部分では誤差が大きくなる。
  過学習に陥りやすいと改めて実感。  
      
* Ridge回帰を単回帰と多項式に当てはめる  
  * モデル  
  モデルは回帰モデルに、罰則項を追加したものとなる。
  パラメータｗはそのとき以下の通りに表現される。
    $$ w\quad = \quad {(\tilde{X}^T \tilde{X}+\lambda I)}^{-1} \tilde{X}^T \boldsymbol{y} $$  
    λが罰則項となり、誤差を小さくしつつ、パラメータｗも小さくなるように調整する項となる。
    これにより、外れ値などの影響を受けづらくなる。
  
  * 実装  
  ファイルの`ridge.ipynb`にて実装。


## ３章　ロジスティック回帰  
* モデル  
ロジスティック回帰は、回帰モデルを確率に変換しているモデル。
二値分類に使用される。  
回帰とは異なり二値分類のため、予測値は実数全体ではなく、０か１となる。そのため回帰モデルにシグモイド関数をかけたモデル。  
  $$ 予測値　\hat{P_i} \quad = \quad h =\quad \sigma(\theta_0 + \theta_1 x_{i,1} + \theta_2 x_{i,2}+...+\theta_m x_{i,m}) = \sigma\quad(\boldsymbol{\theta}^T\quad\boldsymbol{\tilde{x}^T})\\
  損失関数　E \quad = \quad - \sum \bigl({y_i\log h + (1-y)\log (1-h) \bigr)} 
$$  
  損失関数は尤度関数で、さらにそれを対数を取って総和の式にし計算をしやすくしたものが上記の式（対数尤度関数）となる。
  対数を取るのは総乗から、総和に変換するのと、確率どうしの乗算により小さすぎる数字となり桁落ちしてしまうことを防ぐ。 

  
* 実装  
ファイルの`logistickaiki.ipynb`にて実装。
損失関数については、解析的に求められないため、数値計算として
勾配降下法を用いた。
